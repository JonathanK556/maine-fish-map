{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explore 2025 Stocking Data\n",
        "\n",
        "This notebook explores the new 2025 stocking data and identifies:\n",
        "- Bodies of water that are new (not in existing 2024 data)\n",
        "- Bodies of water that are missing coordinates\n",
        "- Differences between 2024 and 2025 data\n",
        "\n",
        "**Goal:** Prepare for updating the map with 2025 data while preserving pike and char data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025 Data Shape: (2207, 21)\n",
            "\n",
            "Columns: ['Id', 'WATCODE', 'WATER', 'TOWN', 'COUNTY', 'REGION', 'SPP', 'STRAIN', 'AGEGRP', 'QTYRequested', 'QTYDelivered', 'KGs', 'mm', 'Inches', 'MARKS', 'DeliveryDate', 'HATCHERY', 'ORDER TYPE', 'SITE', 'COMMENTS', 'NOTE']\n",
            "\n",
            "First few rows:\n",
            "\n",
            "Data types:\n",
            "Id                       int64\n",
            "WATCODE                 object\n",
            "WATER                   object\n",
            "TOWN                    object\n",
            "COUNTY                  object\n",
            "REGION                  object\n",
            "SPP                     object\n",
            "STRAIN                   int64\n",
            "AGEGRP                  object\n",
            "QTYRequested             int64\n",
            "QTYDelivered             int64\n",
            "KGs                    float64\n",
            "mm                       int64\n",
            "Inches                   int64\n",
            "MARKS                   object\n",
            "DeliveryDate    datetime64[ns]\n",
            "HATCHERY                object\n",
            "ORDER TYPE              object\n",
            "SITE                    object\n",
            "COMMENTS                object\n",
            "NOTE                    object\n",
            "dtype: object\n",
            "\n",
            "Sample values from each column:\n",
            "\n",
            "Id: [46266 50951 50952 50950 47177 47176 47186 47178 46686 46645]\n",
            "\n",
            "WATCODE: ['3760' '043031' '043034' '043' '046009' '04600901' '020' '00801408' '019'\n",
            " '016']\n",
            "\n",
            "WATER: ['RANGE P (LOWER)' 'SONGO R' 'JORDAN R' 'PRESUMPSCOT R' 'COLLYER B'\n",
            " 'BRANDY B' 'OGUNQUIT R' 'WORSTER B' 'JOSIAS R' 'CAPE NEDDICK R']\n",
            "\n",
            "TOWN: ['Poland' 'Casco' 'Raymond' 'Windham' 'Gray' 'New Gloucester' 'Wells'\n",
            " 'Berwick' 'York' 'Kennebunkport']\n",
            "\n",
            "COUNTY: ['Androscoggin' 'Cumberland' 'York' 'Oxford' 'Sagadahoc' 'Penobscot'\n",
            " 'Somerset' 'Kennebec' 'Lincoln' 'Knox']\n",
            "\n",
            "REGION: ['A' 'B' 'C' 'D' 'E' 'F' 'G']\n",
            "\n",
            "SPP: ['BKT' 'SPK' 'BNT' 'RBT' 'LKT' 'LLS']\n",
            "\n",
            "STRAIN: [21 38 79 43 81 64 67 10 51 53]\n",
            "\n",
            "AGEGRP: ['AY' 'SY' 'FRY' 'FF' 'AFF' 'FY' 'AD']\n",
            "\n",
            "QTYRequested: [300 100 200  75 150 500 350 125 800 225]\n",
            "\n",
            "QTYDelivered: [300 100 200  75 150 500 350 125 800 225]\n",
            "\n",
            "KGs: [150.  70. 140.  17.  13.  25.  34.  84.  43.  65.]\n",
            "\n",
            "mm: [350 402 250 260 266 228 240 258 235 255]\n",
            "\n",
            "Inches: [14 16 10  9  8 11  2  6  7 15]\n",
            "\n",
            "MARKS: [nan 'AD' 'RVAD' 'RV' 'BV' 'LVAD' 'LV' 'LP' 'LPAD']\n",
            "\n",
            "DeliveryDate: <DatetimeArray>\n",
            "['2025-02-11 00:00:00', '2025-04-03 00:00:00', '2025-04-07 00:00:00',\n",
            " '2025-04-08 00:00:00', '2025-04-10 00:00:00', '2025-04-11 00:00:00',\n",
            " '2025-04-15 00:00:00', '2025-04-16 00:00:00', '2025-04-17 00:00:00',\n",
            " '2025-04-18 00:00:00']\n",
            "Length: 10, dtype: datetime64[ns]\n",
            "\n",
            "HATCHERY: ['DRY MILLS' 'GOV HILL' 'CASCO' 'NEW GLST' 'ENFIELD' 'EMBDEN' 'PALERMO'\n",
            " 'GRAND LAKE' 'DEAD RIVER']\n",
            "\n",
            "ORDER TYPE: ['Scheduled' 'Unscheduled' 'Add Change' 'Legislative']\n",
            "\n",
            "SITE: ['STATE PARK' 'BELOW LOCKS' 'BELOW PANTHER RUN DAM OFF MILL ST.'\n",
            " 'RTE. 35 XING' 'MERRILL RD. XING' 'MEGUIRE RD. XING' 'MORSE RD. XING'\n",
            " 'RTE. 100 XING' 'CAPTAIN THOMAS RD. XING' 'RTE. 236 XING']\n",
            "\n",
            "COMMENTS: ['MDIFW R3 EVENT - COORDINATE W/ CHELSEA' 'UNSCHEDULED' 'LATE APRIL' nan\n",
            " 'EARLY APRIL' 'GATED - CONTACT CHRIS SHAW @ 329-4225' 'MID APRIL'\n",
            " 'CONTACT NORM LAMBERT @ 432-7706 TO MOVE ROCKS'\n",
            " 'GATE - CONTACT SHAWN DOUGHTY @ 603-770-4871 or 603-294-5146'\n",
            " 'LATE APRIL; NEW SITE']\n",
            "\n",
            "NOTE: ['Cancelled order, then reinstated with extra males for Extravaganza'\n",
            " 'Added per Reg. A' nan 'Added 75 per Reg. A'\n",
            " 'Switched from FY to SY - Due to NG shutdown' 'Collateral triploids'\n",
            " 'Removed Derby Comments'\n",
            " 'Switched to SY program, Ameneded for triploid study per Reg. A'\n",
            " 'Amended for triploid study per Reg. A' 'Amended info per Reg. A']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jonathan/Library/Python/3.9/lib/python/site-packages/openpyxl/worksheet/header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
            "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
          ]
        }
      ],
      "source": [
        "# Load 2025 stocking data\n",
        "df_2025 = pd.read_excel('2025_Stocking.xlsx')\n",
        "\n",
        "print(f\"2025 Data Shape: {df_2025.shape}\")\n",
        "print(f\"\\nColumns: {df_2025.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_2025.head()\n",
        "\n",
        "# Show data types and sample values\n",
        "print(f\"\\nData types:\")\n",
        "print(df_2025.dtypes)\n",
        "print(f\"\\nSample values from each column:\")\n",
        "for col in df_2025.columns:\n",
        "    print(f\"\\n{col}: {df_2025[col].unique()[:10]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Data Shape: (2250, 10)\n",
            "\n",
            "Columns: ['COUNTY', 'DATE', 'WATER', 'TOWN', 'SPECIES', 'QTY', 'SIZE (inch)', 'X_coord', 'Y_coord', 'ABUNDANCE']\n",
            "\n",
            "Unique species in current data: ['ARCTIC CHAR', 'BROOK TROUT', 'BROWN TROUT', 'L.L. SALMON', 'LAKE TROUT', 'NORTHERN PIKE', 'RAINBOW TROUT', 'SPLAKE']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COUNTY</th>\n",
              "      <th>DATE</th>\n",
              "      <th>WATER</th>\n",
              "      <th>TOWN</th>\n",
              "      <th>SPECIES</th>\n",
              "      <th>QTY</th>\n",
              "      <th>SIZE (inch)</th>\n",
              "      <th>X_coord</th>\n",
              "      <th>Y_coord</th>\n",
              "      <th>ABUNDANCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>2025-02-11</td>\n",
              "      <td>RANGE P (LOWER)</td>\n",
              "      <td>Poland</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>300.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-70.369148</td>\n",
              "      <td>44.043731</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cumberland</td>\n",
              "      <td>2025-04-03</td>\n",
              "      <td>SONGO R</td>\n",
              "      <td>Casco</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>100.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>-70.574503</td>\n",
              "      <td>43.930731</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cumberland</td>\n",
              "      <td>2025-04-03</td>\n",
              "      <td>JORDAN R</td>\n",
              "      <td>Raymond</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>100.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>-70.462052</td>\n",
              "      <td>43.896887</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cumberland</td>\n",
              "      <td>2025-04-03</td>\n",
              "      <td>PRESUMPSCOT R</td>\n",
              "      <td>Windham</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>200.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>-70.410724</td>\n",
              "      <td>43.717251</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cumberland</td>\n",
              "      <td>2025-04-07</td>\n",
              "      <td>COLLYER B</td>\n",
              "      <td>Gray</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-70.302713</td>\n",
              "      <td>43.905907</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         COUNTY        DATE            WATER     TOWN      SPECIES    QTY  \\\n",
              "0  Androscoggin  2025-02-11  RANGE P (LOWER)   Poland  BROOK TROUT  300.0   \n",
              "1    Cumberland  2025-04-03          SONGO R    Casco  BROOK TROUT  100.0   \n",
              "2    Cumberland  2025-04-03         JORDAN R  Raymond  BROOK TROUT  100.0   \n",
              "3    Cumberland  2025-04-03    PRESUMPSCOT R  Windham  BROOK TROUT  200.0   \n",
              "4    Cumberland  2025-04-07        COLLYER B     Gray  BROOK TROUT  100.0   \n",
              "\n",
              "   SIZE (inch)    X_coord    Y_coord ABUNDANCE  \n",
              "0         14.0 -70.369148  44.043731       NaN  \n",
              "1         16.0 -70.574503  43.930731       NaN  \n",
              "2         16.0 -70.462052  43.896887       NaN  \n",
              "3         16.0 -70.410724  43.717251       NaN  \n",
              "4         10.0 -70.302713  43.905907       NaN  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load existing combined data\n",
        "df_current = pd.read_csv('df_updated.csv')\n",
        "\n",
        "print(f\"Current Data Shape: {df_current.shape}\")\n",
        "print(f\"\\nColumns: {df_current.columns.tolist()}\")\n",
        "print(f\"\\nUnique species in current data: {sorted(df_current['SPECIES'].unique())}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_current.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standardized columns in 2025 data:\n",
            "['TOWN', 'DATE', 'WATER', 'COUNTY', 'SPECIES', 'QTY', 'SIZE (inch)']\n",
            "\n",
            "Species codes found and mapped:\n",
            "Unique species values: ['BROOK TROUT', 'BROWN TROUT', 'L.L. SALMON', 'LAKE TROUT', 'RAINBOW TROUT', 'SPLAKE']\n",
            "\n",
            "Data shape: (2207, 7)\n",
            "\n",
            "First few rows after standardization:\n"
          ]
        }
      ],
      "source": [
        "# Standardize 2025 data - we need: TOWN, DATE, WATER, COUNTY, SPECIES, QTY, SIZE (inch)\n",
        "# First normalize column names to uppercase\n",
        "df_2025.columns = df_2025.columns.str.strip().str.upper()\n",
        "\n",
        "# Map actual column names to standard names based on what we see in the data\n",
        "# From the output: DELIVERYDATE -> DATE, INCHES -> SIZE (inch), QTYDELIVERED -> QTY, SPP -> SPECIES\n",
        "column_mapping = {\n",
        "    'DELIVERYDATE': 'DATE',\n",
        "    'DATE': 'DATE',  # Keep if already named correctly\n",
        "    'INCHES': 'SIZE (inch)',\n",
        "    'QTYDELIVERED': 'QTY',  # Use delivered quantity\n",
        "    'QTYREQUESTED': 'QTY',  # Fallback to requested if delivered not available\n",
        "    'QUANTITY': 'QTY',\n",
        "    'SPP': 'SPECIES',  # Species code column\n",
        "    'SPECIES': 'SPECIES'  # Keep if already named correctly\n",
        "}\n",
        "\n",
        "# Rename columns based on mapping (prioritize first match)\n",
        "for old_name, new_name in column_mapping.items():\n",
        "    if old_name in df_2025.columns:\n",
        "        if new_name not in df_2025.columns or old_name == new_name:\n",
        "            df_2025 = df_2025.rename(columns={old_name: new_name})\n",
        "\n",
        "# Handle QTY - use QTYDELIVERED if available, otherwise QTYREQUESTED\n",
        "if 'QTYDELIVERED' in df_2025.columns and 'QTY' not in df_2025.columns:\n",
        "    df_2025['QTY'] = df_2025['QTYDELIVERED']\n",
        "elif 'QTYREQUESTED' in df_2025.columns and 'QTY' not in df_2025.columns:\n",
        "    df_2025['QTY'] = df_2025['QTYREQUESTED']\n",
        "\n",
        "# Map species codes to full species names\n",
        "# BKT = brook trout, RBT = rainbow trout, LKT = lake trout, \n",
        "# BNT = brown trout, LLS = landlocked salmon, SPK = splake\n",
        "species_code_mapping = {\n",
        "    'BKT': 'BROOK TROUT',\n",
        "    'RBT': 'RAINBOW TROUT',\n",
        "    'LKT': 'LAKE TROUT',\n",
        "    'BNT': 'BROWN TROUT',\n",
        "    'LLS': 'L.L. SALMON',\n",
        "    'SPK': 'SPLAKE'\n",
        "}\n",
        "\n",
        "# Convert species codes to full names\n",
        "if 'SPECIES' in df_2025.columns:\n",
        "    df_2025['SPECIES'] = df_2025['SPECIES'].str.strip().str.upper().map(\n",
        "        lambda x: species_code_mapping.get(x, x) if pd.notna(x) else x\n",
        "    )\n",
        "\n",
        "# Select only the columns we need: TOWN, DATE, WATER, COUNTY, SPECIES, QTY, SIZE (inch)\n",
        "required_columns = ['TOWN', 'DATE', 'WATER', 'COUNTY', 'SPECIES', 'QTY', 'SIZE (inch)']\n",
        "available_columns = [col for col in required_columns if col in df_2025.columns]\n",
        "\n",
        "# Keep only required columns\n",
        "df_2025_clean = df_2025[available_columns].copy()\n",
        "\n",
        "# Add missing columns as None if they don't exist\n",
        "for col in required_columns:\n",
        "    if col not in df_2025_clean.columns:\n",
        "        df_2025_clean[col] = None\n",
        "        print(f\"Warning: Column '{col}' not found in 2025 data - added as None\")\n",
        "\n",
        "# Reorder columns to match required order\n",
        "df_2025_clean = df_2025_clean[required_columns]\n",
        "\n",
        "print(\"Standardized columns in 2025 data:\")\n",
        "print(df_2025_clean.columns.tolist())\n",
        "print(f\"\\nSpecies codes found and mapped:\")\n",
        "print(f\"Unique species values: {sorted(df_2025_clean['SPECIES'].dropna().unique())}\")\n",
        "print(f\"\\nData shape: {df_2025_clean.shape}\")\n",
        "print(f\"\\nFirst few rows after standardization:\")\n",
        "df_2025_clean.head()\n",
        "\n",
        "# Use the clean dataframe going forward\n",
        "df_2025 = df_2025_clean.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current stocked species data rows: 2207\n",
            "\n",
            "Species in current stocked data: ['BROOK TROUT', 'BROWN TROUT', 'L.L. SALMON', 'LAKE TROUT', 'RAINBOW TROUT', 'SPLAKE']\n",
            "\n",
            "Permanent species data rows: 43\n",
            "Species in permanent data: ['ARCTIC CHAR', 'NORTHERN PIKE']\n"
          ]
        }
      ],
      "source": [
        "# Extract only stocked species from current data (exclude pike and char for now)\n",
        "# These are permanent species that we'll keep\n",
        "permanent_species = ['NORTHERN PIKE', 'ARCTIC CHAR']\n",
        "\n",
        "# Get current stocked species data (trout, salmon, splake - these will be replaced)\n",
        "current_stocked = df_current[~df_current['SPECIES'].isin(permanent_species)].copy()\n",
        "\n",
        "print(f\"Current stocked species data rows: {len(current_stocked)}\")\n",
        "print(f\"\\nSpecies in current stocked data: {sorted(current_stocked['SPECIES'].unique())}\")\n",
        "\n",
        "# Get permanent species data (pike and char - these we'll keep)\n",
        "permanent_data = df_current[df_current['SPECIES'].isin(permanent_species)].copy()\n",
        "print(f\"\\nPermanent species data rows: {len(permanent_data)}\")\n",
        "print(f\"Species in permanent data: {sorted(permanent_data['SPECIES'].unique())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found coordinates for 943 unique waterbody/town combinations\n",
            "\n",
            "Sample of coordinate lookup (first 5):\n",
            "  RANGE P (LOWER), POLAND: (-70.369148, 44.043731)\n",
            "  SONGO R, CASCO: (-70.574503, 43.930731)\n",
            "  JORDAN R, RAYMOND: (-70.462052, 43.896887)\n",
            "  PRESUMPSCOT R, WINDHAM: (-70.410724, 43.717251)\n",
            "  COLLYER B, GRAY: (-70.302713, 43.905907)\n"
          ]
        }
      ],
      "source": [
        "# Create a coordinate lookup from current data\n",
        "# Key: (WATER, TOWN) tuple, Value: (X_coord, Y_coord) tuple\n",
        "coord_lookup = {}\n",
        "\n",
        "for _, row in df_current.iterrows():\n",
        "    if pd.notna(row['X_coord']) and pd.notna(row['Y_coord']):\n",
        "        key = (str(row['WATER']).strip().upper(), str(row['TOWN']).strip().upper())\n",
        "        coord_lookup[key] = (float(row['X_coord']), float(row['Y_coord']))\n",
        "\n",
        "print(f\"Found coordinates for {len(coord_lookup)} unique waterbody/town combinations\")\n",
        "print(f\"\\nSample of coordinate lookup (first 5):\")\n",
        "for i, (key, coords) in enumerate(list(coord_lookup.items())[:5]):\n",
        "    print(f\"  {key[0]}, {key[1]}: ({coords[0]:.6f}, {coords[1]:.6f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique waterbody/town combinations in 2025 data: 921\n",
            "\n",
            "Total rows in 2025 data: 2207\n",
            "\n",
            "Species in 2025 data: ['BROOK TROUT', 'BROWN TROUT', 'L.L. SALMON', 'LAKE TROUT', 'RAINBOW TROUT', 'SPLAKE']\n",
            "\n",
            "Columns in 2025 data: ['TOWN', 'DATE', 'WATER', 'COUNTY', 'SPECIES', 'QTY', 'SIZE (inch)', 'X_coord', 'Y_coord', 'key']\n"
          ]
        }
      ],
      "source": [
        "# Prepare 2025 data for analysis\n",
        "# Add empty coordinate columns (will be filled from existing data or left blank)\n",
        "df_2025_prep = df_2025.copy()\n",
        "df_2025_prep['X_coord'] = None\n",
        "df_2025_prep['Y_coord'] = None\n",
        "\n",
        "# Create standardized keys for matching (WATER, TOWN)\n",
        "df_2025_prep['key'] = df_2025_prep.apply(\n",
        "    lambda row: (str(row['WATER']).strip().upper(), str(row['TOWN']).strip().upper()), \n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Check unique waterbodies in 2025 data\n",
        "unique_2025_locations = df_2025_prep[['WATER', 'TOWN', 'COUNTY']].drop_duplicates()\n",
        "print(f\"Unique waterbody/town combinations in 2025 data: {len(unique_2025_locations)}\")\n",
        "print(f\"\\nTotal rows in 2025 data: {len(df_2025_prep)}\")\n",
        "print(f\"\\nSpecies in 2025 data: {sorted(df_2025_prep['SPECIES'].dropna().unique())}\")\n",
        "print(f\"\\nColumns in 2025 data: {df_2025_prep.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waterbodies WITH coordinates: 2189 rows\n",
            "Waterbodies MISSING coordinates: 18 rows\n",
            "\n",
            "Unique waterbody/town combinations MISSING coordinates: 14\n",
            "\n",
            "Unique waterbody/town combinations WITH coordinates: 908\n"
          ]
        }
      ],
      "source": [
        "# Identify which 2025 waterbodies have coordinates and which don't\n",
        "df_2025_prep['has_coords'] = df_2025_prep['key'].apply(\n",
        "    lambda k: k in coord_lookup\n",
        ")\n",
        "\n",
        "# For those with coordinates, populate them\n",
        "for idx, row in df_2025_prep.iterrows():\n",
        "    if row['has_coords']:\n",
        "        coords = coord_lookup[row['key']]\n",
        "        df_2025_prep.at[idx, 'X_coord'] = coords[0]\n",
        "        df_2025_prep.at[idx, 'Y_coord'] = coords[1]\n",
        "\n",
        "# Get unique locations that are missing coordinates\n",
        "missing_coords = df_2025_prep[~df_2025_prep['has_coords']][['WATER', 'TOWN', 'COUNTY', 'SPECIES']].drop_duplicates()\n",
        "\n",
        "print(f\"Waterbodies WITH coordinates: {df_2025_prep['has_coords'].sum()} rows\")\n",
        "print(f\"Waterbodies MISSING coordinates: {(~df_2025_prep['has_coords']).sum()} rows\")\n",
        "print(f\"\\nUnique waterbody/town combinations MISSING coordinates: {len(missing_coords)}\")\n",
        "print(f\"\\nUnique waterbody/town combinations WITH coordinates: {df_2025_prep[df_2025_prep['has_coords']][['WATER', 'TOWN']].drop_duplicates().shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "LOCATIONS MISSING COORDINATES\n",
            "================================================================================\n",
            "\n",
            "Total unique locations missing coordinates: 14\n",
            "\n",
            "                         WATER                  TOWN     COUNTY     SPECIES\n",
            "            MUSQUACOOK L (2ND)          T11 R11 WELS  Aroostook  LAKE TROUT\n",
            "                    UMSASKIS L          T11 R13 WELS  Aroostook  LAKE TROUT\n",
            "               NICATOUS STREAM                 T3 ND    Hancock BROOK TROUT\n",
            "                       BASIN P               Fayette   Kennebec BROOK TROUT\n",
            "                       BASIN P               Fayette   Kennebec      SPLAKE\n",
            "                      DENNIS B            Litchfield   Kennebec BROOK TROUT\n",
            "                     POTTERS B            Litchfield   Kennebec BROOK TROUT\n",
            "                       FRESH P           North Haven       Knox BROOK TROUT\n",
            "BANGOR MUNICIPAL GOLF COURSE P                Bangor  Penobscot BROOK TROUT\n",
            "                       MOORE P        Bradstreet Twp   Somerset BROOK TROUT\n",
            "                     KNIGHTS P        Squaretown Twp   Somerset BROOK TROUT\n",
            "                         BIG L Grand Lake Stream Plt Washington L.L. SALMON\n",
            "                      BOYDEN L                 Perry Washington L.L. SALMON\n",
            "           SPECTACLE L (UPPER)            T19 ED BPP Washington BROOK TROUT\n"
          ]
        }
      ],
      "source": [
        "# Show locations missing coordinates (sorted by county, town, water)\n",
        "print(\"=\" * 80)\n",
        "print(\"LOCATIONS MISSING COORDINATES\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nTotal unique locations missing coordinates: {len(missing_coords)}\\n\")\n",
        "\n",
        "missing_coords_sorted = missing_coords.sort_values(['COUNTY', 'TOWN', 'WATER'])\n",
        "print(missing_coords_sorted.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "COMPARISON: 2024 vs 2025\n",
            "================================================================================\n",
            "\n",
            "Unique locations in 2024 data: 921\n",
            "Unique locations in 2025 data: 921\n",
            "\n",
            "NEW locations in 2025 (not in 2024): 0\n",
            "REMOVED locations from 2024 (not in 2025): 0\n",
            "Locations in BOTH: 921\n"
          ]
        }
      ],
      "source": [
        "# Compare with 2024 data to identify NEW waterbodies\n",
        "# Get unique locations from 2024 stocked data\n",
        "unique_2024_locations = current_stocked[['WATER', 'TOWN', 'COUNTY']].drop_duplicates()\n",
        "unique_2024_locations['key'] = unique_2024_locations.apply(\n",
        "    lambda row: (str(row['WATER']).strip().upper(), str(row['TOWN']).strip().upper()),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Get unique locations from 2025 data\n",
        "unique_2025_locations_clean = df_2025_prep[['WATER', 'TOWN', 'COUNTY']].drop_duplicates()\n",
        "unique_2025_locations_clean['key'] = unique_2025_locations_clean.apply(\n",
        "    lambda row: (str(row['WATER']).strip().upper(), str(row['TOWN']).strip().upper()),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Find new locations in 2025\n",
        "set_2024 = set(unique_2024_locations['key'].tolist())\n",
        "set_2025 = set(unique_2025_locations_clean['key'].tolist())\n",
        "\n",
        "new_locations = set_2025 - set_2024\n",
        "removed_locations = set_2024 - set_2025\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"COMPARISON: 2024 vs 2025\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nUnique locations in 2024 data: {len(set_2024)}\")\n",
        "print(f\"Unique locations in 2025 data: {len(set_2025)}\")\n",
        "print(f\"\\nNEW locations in 2025 (not in 2024): {len(new_locations)}\")\n",
        "print(f\"REMOVED locations from 2024 (not in 2025): {len(removed_locations)}\")\n",
        "print(f\"Locations in BOTH: {len(set_2024 & set_2025)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "No new locations found in 2025 data.\n"
          ]
        }
      ],
      "source": [
        "# Show new locations in 2025\n",
        "if len(new_locations) > 0:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"NEW LOCATIONS IN 2025 (not present in 2024)\")\n",
        "    print(\"=\" * 80)\n",
        "    new_locations_df = unique_2025_locations_clean[\n",
        "        unique_2025_locations_clean['key'].isin(new_locations)\n",
        "    ][['WATER', 'TOWN', 'COUNTY']].sort_values(['COUNTY', 'TOWN', 'WATER'])\n",
        "    print(f\"\\nTotal new locations: {len(new_locations_df)}\\n\")\n",
        "    print(new_locations_df.to_string(index=False))\n",
        "else:\n",
        "    print(\"\\nNo new locations found in 2025 data.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "No locations were removed (all 2024 locations appear in 2025).\n"
          ]
        }
      ],
      "source": [
        "# Show removed locations (in 2024 but not in 2025)\n",
        "if len(removed_locations) > 0:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"LOCATIONS REMOVED FROM 2024 (not present in 2025)\")\n",
        "    print(\"=\" * 80)\n",
        "    removed_locations_df = unique_2024_locations[\n",
        "        unique_2024_locations['key'].isin(removed_locations)\n",
        "    ][['WATER', 'TOWN', 'COUNTY']].sort_values(['COUNTY', 'TOWN', 'WATER'])\n",
        "    print(f\"\\nTotal removed locations: {len(removed_locations_df)}\\n\")\n",
        "    print(removed_locations_df.to_string(index=False))\n",
        "else:\n",
        "    print(\"\\nNo locations were removed (all 2024 locations appear in 2025).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SUMMARY: Locations Missing Coordinates\n",
            "================================================================================\n",
            "\n",
            "Total unique locations missing coordinates: 13\n",
            "\n",
            "Breakdown by county:\n",
            "COUNTY\n",
            "Kennebec      3\n",
            "Washington    3\n",
            "Aroostook     2\n",
            "Somerset      2\n",
            "Hancock       1\n",
            "Knox          1\n",
            "Penobscot     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "First 20 locations (full list below):\n",
            "                         WATER                  TOWN     COUNTY X_coord Y_coord\n",
            "            MUSQUACOOK L (2ND)          T11 R11 WELS  Aroostook    None    None\n",
            "                    UMSASKIS L          T11 R13 WELS  Aroostook    None    None\n",
            "               NICATOUS STREAM                 T3 ND    Hancock    None    None\n",
            "                       BASIN P               Fayette   Kennebec    None    None\n",
            "                      DENNIS B            Litchfield   Kennebec    None    None\n",
            "                     POTTERS B            Litchfield   Kennebec    None    None\n",
            "                       FRESH P           North Haven       Knox    None    None\n",
            "BANGOR MUNICIPAL GOLF COURSE P                Bangor  Penobscot    None    None\n",
            "                       MOORE P        Bradstreet Twp   Somerset    None    None\n",
            "                     KNIGHTS P        Squaretown Twp   Somerset    None    None\n",
            "                         BIG L Grand Lake Stream Plt Washington    None    None\n",
            "                      BOYDEN L                 Perry Washington    None    None\n",
            "           SPECTACLE L (UPPER)            T19 ED BPP Washington    None    None\n"
          ]
        }
      ],
      "source": [
        "# Create a summary DataFrame of locations missing coordinates\n",
        "# This will be useful for manually adding coordinates later\n",
        "missing_coords_summary = df_2025_prep[~df_2025_prep['has_coords']][\n",
        "    ['WATER', 'TOWN', 'COUNTY']\n",
        "].drop_duplicates().sort_values(['COUNTY', 'TOWN', 'WATER'])\n",
        "\n",
        "# Add columns for manually entering coordinates (initially blank)\n",
        "missing_coords_summary['X_coord'] = None\n",
        "missing_coords_summary['Y_coord'] = None\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"SUMMARY: Locations Missing Coordinates\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nTotal unique locations missing coordinates: {len(missing_coords_summary)}\")\n",
        "if len(missing_coords_summary) > 0:\n",
        "    print(f\"\\nBreakdown by county:\")\n",
        "    print(missing_coords_summary['COUNTY'].value_counts())\n",
        "    print(f\"\\nFirst 20 locations (full list below):\")\n",
        "    print(missing_coords_summary.head(20).to_string(index=False))\n",
        "else:\n",
        "    print(\"\\n✅ All locations have coordinates!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved missing coordinates to 'missing_coordinates_2025.csv'\n",
            "\n",
            "This file can be used to manually add coordinates.\n",
            "After adding coordinates, you can use this file to update the main dataset.\n"
          ]
        }
      ],
      "source": [
        "# Save missing coordinates to CSV for manual coordinate entry\n",
        "# NOTE: Only run this ONCE before manually adding coordinates!\n",
        "# Commented out to prevent overwriting manually entered coordinates\n",
        "# missing_coords_summary.to_csv('missing_coordinates_2025.csv', index=False)\n",
        "# print(\"✅ Saved missing coordinates to 'missing_coordinates_2025.csv'\")\n",
        "print(\"⚠️  Skipping save to prevent overwriting manually entered coordinates\")\n",
        "print(f\"Current missing_coordinates_2025.csv has {len(missing_coords_summary)} locations\")\n",
        "print(f\"\\nTo regenerate the file, uncomment the lines above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. **Review the missing coordinates list** - Check `missing_coordinates_2025.csv`\n",
        "2. **Manually add coordinates** - Fill in X_coord and Y_coord columns for new locations\n",
        "3. **Create update script** - Build a script that:\n",
        "   - Loads 2025 data\n",
        "   - Merges in coordinates (from existing data + manually added)\n",
        "   - Combines with permanent species data (pike and char)\n",
        "   - Saves as updated `df_updated.csv`\n",
        "4. **Update the map** - The map will automatically use the new data\n",
        "\n",
        "**Note:** The lakefish survey data (`LakeFish_Maine.xls`) is available but will be handled separately in the future.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DATA SUMMARY\n",
            "================================================================================\n",
            "\n",
            "2025 Stocking Data:\n",
            "  Total rows: 2207\n",
            "  Unique locations: 921\n",
            "  Species: BROOK TROUT, BROWN TROUT, L.L. SALMON, LAKE TROUT, RAINBOW TROUT, SPLAKE\n",
            "  Columns: TOWN, DATE, WATER, COUNTY, SPECIES, QTY, SIZE (inch), X_coord, Y_coord, key, has_coords\n",
            "\n",
            "Current Combined Data:\n",
            "  Total rows: 2250\n",
            "  Stocked species rows: 2207\n",
            "  Permanent species rows (to keep): 43\n",
            "\n",
            "Coordinate Status:\n",
            "  Locations with coordinates: 2189 rows\n",
            "  Locations missing coordinates: 18 rows\n",
            "  Unique locations missing coordinates: 13\n",
            "\n",
            "Comparison (2024 vs 2025):\n",
            "  New locations in 2025: 0\n",
            "  Removed locations from 2024: 0\n",
            "  Locations in both: 921\n"
          ]
        }
      ],
      "source": [
        "# Quick stats summary\n",
        "print(\"=\" * 80)\n",
        "print(\"DATA SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n2025 Stocking Data:\")\n",
        "print(f\"  Total rows: {len(df_2025_prep)}\")\n",
        "print(f\"  Unique locations: {len(unique_2025_locations_clean)}\")\n",
        "print(f\"  Species: {', '.join(sorted(df_2025_prep['SPECIES'].dropna().unique()))}\")\n",
        "print(f\"  Columns: {', '.join(df_2025_prep.columns.tolist())}\")\n",
        "\n",
        "print(f\"\\nCurrent Combined Data:\")\n",
        "print(f\"  Total rows: {len(df_current)}\")\n",
        "print(f\"  Stocked species rows: {len(current_stocked)}\")\n",
        "print(f\"  Permanent species rows (to keep): {len(permanent_data)}\")\n",
        "\n",
        "print(f\"\\nCoordinate Status:\")\n",
        "print(f\"  Locations with coordinates: {df_2025_prep['has_coords'].sum()} rows\")\n",
        "print(f\"  Locations missing coordinates: {(~df_2025_prep['has_coords']).sum()} rows\")\n",
        "print(f\"  Unique locations missing coordinates: {len(missing_coords_summary)}\")\n",
        "\n",
        "print(f\"\\nComparison (2024 vs 2025):\")\n",
        "print(f\"  New locations in 2025: {len(new_locations)}\")\n",
        "print(f\"  Removed locations from 2024: {len(removed_locations)}\")\n",
        "print(f\"  Locations in both: {len(set_2024 & set_2025)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Update Data with 2025 Stocking Data\n",
        "\n",
        "Run the cells below to:\n",
        "1. Load 2025 data with updated coordinates\n",
        "2. Merge coordinates from existing data and manually added coordinates\n",
        "3. Combine with permanent species (pike and char)\n",
        "4. Update df_updated.csv\n",
        "5. Create coordinate_reference.csv for future use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 13 manually added coordinates\n"
          ]
        }
      ],
      "source": [
        "# Load manually added coordinates from missing_coordinates_2025.csv\n",
        "manual_coords = {}\n",
        "df_manual = pd.read_csv('missing_coordinates_2025.csv')\n",
        "for _, row in df_manual.iterrows():\n",
        "    if pd.notna(row['X_coord']) and pd.notna(row['Y_coord']):\n",
        "        key = (str(row['WATER']).strip().upper(), str(row['TOWN']).strip().upper())\n",
        "        manual_coords[key] = (float(row['X_coord']), float(row['Y_coord']))\n",
        "\n",
        "print(f\"Loaded {len(manual_coords)} manually added coordinates\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows with coordinates: 2207\n",
            "Rows missing coordinates: 0\n",
            "\n",
            "✅ All locations have coordinates!\n"
          ]
        }
      ],
      "source": [
        "# Merge manual coordinates into 2025 data (prioritize manual over existing)\n",
        "for idx, row in df_2025_prep.iterrows():\n",
        "    key = (str(row['WATER']).strip().upper(), str(row['TOWN']).strip().upper())\n",
        "    \n",
        "    # Prioritize manual coordinates, then existing\n",
        "    if key in manual_coords:\n",
        "        df_2025_prep.at[idx, 'X_coord'] = manual_coords[key][0]\n",
        "        df_2025_prep.at[idx, 'Y_coord'] = manual_coords[key][1]\n",
        "    elif key in coord_lookup:\n",
        "        df_2025_prep.at[idx, 'X_coord'] = coord_lookup[key][0]\n",
        "        df_2025_prep.at[idx, 'Y_coord'] = coord_lookup[key][1]\n",
        "\n",
        "# Check coordinate status after merge\n",
        "has_coords = df_2025_prep['X_coord'].notna() & df_2025_prep['Y_coord'].notna()\n",
        "print(f\"Rows with coordinates: {has_coords.sum()}\")\n",
        "print(f\"Rows missing coordinates: {(~has_coords).sum()}\")\n",
        "\n",
        "if (~has_coords).sum() > 0:\n",
        "    missing = df_2025_prep[~has_coords][['WATER', 'TOWN', 'COUNTY']].drop_duplicates()\n",
        "    print(f\"\\n⚠️  Warning: {len(missing)} unique locations still missing coordinates\")\n",
        "    print(missing.head(10).to_string(index=False))\n",
        "else:\n",
        "    print(\"\\n✅ All locations have coordinates!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025 data ready: 2207 rows\n",
            "Columns: ['COUNTY', 'DATE', 'WATER', 'TOWN', 'SPECIES', 'QTY', 'SIZE (inch)', 'X_coord', 'Y_coord']\n",
            "Data types - QTY: Int64, SIZE (inch): Int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COUNTY</th>\n",
              "      <th>DATE</th>\n",
              "      <th>WATER</th>\n",
              "      <th>TOWN</th>\n",
              "      <th>SPECIES</th>\n",
              "      <th>QTY</th>\n",
              "      <th>SIZE (inch)</th>\n",
              "      <th>X_coord</th>\n",
              "      <th>Y_coord</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>2025-02-11</td>\n",
              "      <td>RANGE P (LOWER)</td>\n",
              "      <td>Poland</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>300</td>\n",
              "      <td>14</td>\n",
              "      <td>-70.369148</td>\n",
              "      <td>44.043731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cumberland</td>\n",
              "      <td>2025-04-03</td>\n",
              "      <td>SONGO R</td>\n",
              "      <td>Casco</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>100</td>\n",
              "      <td>16</td>\n",
              "      <td>-70.574503</td>\n",
              "      <td>43.930731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cumberland</td>\n",
              "      <td>2025-04-03</td>\n",
              "      <td>JORDAN R</td>\n",
              "      <td>Raymond</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>100</td>\n",
              "      <td>16</td>\n",
              "      <td>-70.462052</td>\n",
              "      <td>43.896887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cumberland</td>\n",
              "      <td>2025-04-03</td>\n",
              "      <td>PRESUMPSCOT R</td>\n",
              "      <td>Windham</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>200</td>\n",
              "      <td>16</td>\n",
              "      <td>-70.410724</td>\n",
              "      <td>43.717251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cumberland</td>\n",
              "      <td>2025-04-07</td>\n",
              "      <td>COLLYER B</td>\n",
              "      <td>Gray</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>-70.302713</td>\n",
              "      <td>43.905907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         COUNTY       DATE            WATER     TOWN      SPECIES  QTY  \\\n",
              "0  Androscoggin 2025-02-11  RANGE P (LOWER)   Poland  BROOK TROUT  300   \n",
              "1    Cumberland 2025-04-03          SONGO R    Casco  BROOK TROUT  100   \n",
              "2    Cumberland 2025-04-03         JORDAN R  Raymond  BROOK TROUT  100   \n",
              "3    Cumberland 2025-04-03    PRESUMPSCOT R  Windham  BROOK TROUT  200   \n",
              "4    Cumberland 2025-04-07        COLLYER B     Gray  BROOK TROUT  100   \n",
              "\n",
              "   SIZE (inch)    X_coord    Y_coord  \n",
              "0           14 -70.369148  44.043731  \n",
              "1           16 -70.574503  43.930731  \n",
              "2           16 -70.462052  43.896887  \n",
              "3           16 -70.410724  43.717251  \n",
              "4           10 -70.302713  43.905907  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Prepare 2025 data for final output - select only required columns\n",
        "# Remove temporary columns (key, has_coords)\n",
        "df_2025_final = df_2025_prep[['COUNTY', 'DATE', 'WATER', 'TOWN', 'SPECIES', 'QTY', 'SIZE (inch)', 'X_coord', 'Y_coord']].copy()\n",
        "\n",
        "# Convert QTY and SIZE (inch) to integers using Int64 (nullable integer) dtype\n",
        "# This allows integers with NaN values and saves as integers in CSV\n",
        "df_2025_final['QTY'] = df_2025_final['QTY'].apply(\n",
        "    lambda x: int(float(x)) if pd.notna(x) and str(x).strip() != '' else pd.NA\n",
        ").astype('Int64')\n",
        "\n",
        "df_2025_final['SIZE (inch)'] = df_2025_final['SIZE (inch)'].apply(\n",
        "    lambda x: int(float(x)) if pd.notna(x) and str(x).strip() != '' else pd.NA\n",
        ").astype('Int64')\n",
        "\n",
        "# Ensure proper column order\n",
        "df_2025_final = df_2025_final[['COUNTY', 'DATE', 'WATER', 'TOWN', 'SPECIES', 'QTY', 'SIZE (inch)', 'X_coord', 'Y_coord']]\n",
        "\n",
        "print(f\"2025 data ready: {len(df_2025_final)} rows\")\n",
        "print(f\"Columns: {df_2025_final.columns.tolist()}\")\n",
        "print(f\"Data types - QTY: {df_2025_final['QTY'].dtype}, SIZE (inch): {df_2025_final['SIZE (inch)'].dtype}\")\n",
        "df_2025_final.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Permanent species data: 44 rows\n",
            "  Arctic Char: 14 rows\n",
            "  Northern Pike: 29 rows\n",
            "Species: ['ARCTIC CHAR', 'NORTHENR PIKE', 'NORTHERN PIKE']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COUNTY</th>\n",
              "      <th>DATE</th>\n",
              "      <th>WATER</th>\n",
              "      <th>TOWN</th>\n",
              "      <th>SPECIES</th>\n",
              "      <th>QTY</th>\n",
              "      <th>SIZE (inch)</th>\n",
              "      <th>X_coord</th>\n",
              "      <th>Y_coord</th>\n",
              "      <th>ABUNDANCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Aroostook</td>\n",
              "      <td>None</td>\n",
              "      <td>BLACK P</td>\n",
              "      <td>T15R9 WELS</td>\n",
              "      <td>ARCTIC CHAR</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>-68.839522</td>\n",
              "      <td>46.974063</td>\n",
              "      <td>High</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Aroostook</td>\n",
              "      <td>None</td>\n",
              "      <td>DEBOULLIE P</td>\n",
              "      <td>T15R9 WELS</td>\n",
              "      <td>ARCTIC CHAR</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>-68.855618</td>\n",
              "      <td>46.965112</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Aroostook</td>\n",
              "      <td>None</td>\n",
              "      <td>GARDNER P</td>\n",
              "      <td>T15R9 WELS</td>\n",
              "      <td>ARCTIC CHAR</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>-68.885971</td>\n",
              "      <td>46.960960</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aroostook</td>\n",
              "      <td>None</td>\n",
              "      <td>PUSHINEER P</td>\n",
              "      <td>T15R9 WELS</td>\n",
              "      <td>ARCTIC CHAR</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>-68.841245</td>\n",
              "      <td>46.960786</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Franklin</td>\n",
              "      <td>None</td>\n",
              "      <td>LONG P</td>\n",
              "      <td>Township E</td>\n",
              "      <td>ARCTIC CHAR</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>-70.089434</td>\n",
              "      <td>45.626023</td>\n",
              "      <td>High</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      COUNTY  DATE        WATER        TOWN      SPECIES   QTY SIZE (inch)  \\\n",
              "0  Aroostook  None      BLACK P  T15R9 WELS  ARCTIC CHAR  None        None   \n",
              "1  Aroostook  None  DEBOULLIE P  T15R9 WELS  ARCTIC CHAR  None        None   \n",
              "2  Aroostook  None    GARDNER P  T15R9 WELS  ARCTIC CHAR  None        None   \n",
              "3  Aroostook  None  PUSHINEER P  T15R9 WELS  ARCTIC CHAR  None        None   \n",
              "4   Franklin  None       LONG P  Township E  ARCTIC CHAR  None        None   \n",
              "\n",
              "     X_coord    Y_coord ABUNDANCE  \n",
              "0 -68.839522  46.974063      High  \n",
              "1 -68.855618  46.965112  Moderate  \n",
              "2 -68.885971  46.960960  Moderate  \n",
              "3 -68.841245  46.960786       Low  \n",
              "4 -70.089434  45.626023      High  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load permanent species data directly from char.csv and pike.csv\n",
        "# This ensures we get ALL locations, including any that might be missing from df_current\n",
        "char_df = pd.read_csv('char.csv')\n",
        "pike_df = pd.read_csv('pike.csv')\n",
        "\n",
        "# Standardize char.csv columns (column names are swapped: Y_coord=lat, X_coord=lon)\n",
        "# We need: X_coord=longitude, Y_coord=latitude\n",
        "char_df = char_df.rename(columns={'Y_coord': 'Y_coord_lat', 'X_coord': 'X_coord_lon'})\n",
        "char_df['X_coord'] = char_df['X_coord_lon']  # X_coord = longitude\n",
        "char_df['Y_coord'] = char_df['Y_coord_lat']  # Y_coord = latitude\n",
        "char_df = char_df.drop(columns=['Y_coord_lat', 'X_coord_lon'])\n",
        "\n",
        "# Standardize pike.csv columns (column names are swapped: Y_coord=lat, X_coord=lon)\n",
        "pike_df = pike_df.rename(columns={'Y_coord': 'Y_coord_lat', 'X_coord': 'X_coord_lon'})\n",
        "pike_df['X_coord'] = pike_df['X_coord_lon']  # X_coord = longitude\n",
        "pike_df['Y_coord'] = pike_df['Y_coord_lat']  # Y_coord = latitude\n",
        "pike_df = pike_df.drop(columns=['Y_coord_lat', 'X_coord_lon'])\n",
        "\n",
        "# Add missing columns to match expected format\n",
        "# char.csv has ABUNDANCE, pike.csv doesn't\n",
        "if 'ABUNDANCE' not in pike_df.columns:\n",
        "    pike_df['ABUNDANCE'] = None\n",
        "if 'DATE' not in char_df.columns:\n",
        "    char_df['DATE'] = None\n",
        "if 'DATE' not in pike_df.columns:\n",
        "    pike_df['DATE'] = None\n",
        "if 'QTY' not in char_df.columns:\n",
        "    char_df['QTY'] = None\n",
        "if 'QTY' not in pike_df.columns:\n",
        "    pike_df['QTY'] = None\n",
        "if 'SIZE (inch)' not in char_df.columns:\n",
        "    char_df['SIZE (inch)'] = None\n",
        "if 'SIZE (inch)' not in pike_df.columns:\n",
        "    pike_df['SIZE (inch)'] = None\n",
        "\n",
        "# Combine char and pike data\n",
        "permanent_data = pd.concat([char_df, pike_df], ignore_index=True)\n",
        "\n",
        "# Ensure proper column order\n",
        "column_order = ['COUNTY', 'DATE', 'WATER', 'TOWN', 'SPECIES', 'QTY', 'SIZE (inch)', 'X_coord', 'Y_coord', 'ABUNDANCE']\n",
        "permanent_data = permanent_data[column_order]\n",
        "\n",
        "print(f\"Permanent species data: {len(permanent_data)} rows\")\n",
        "print(f\"  Arctic Char: {len(permanent_data[permanent_data['SPECIES']=='ARCTIC CHAR'])} rows\")\n",
        "print(f\"  Northern Pike: {len(permanent_data[permanent_data['SPECIES']=='NORTHERN PIKE'])} rows\")\n",
        "print(f\"Species: {sorted(permanent_data['SPECIES'].unique())}\")\n",
        "permanent_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined dataset: 2251 rows\n",
            "\n",
            "Species breakdown:\n",
            "SPECIES\n",
            "ARCTIC CHAR        14\n",
            "BROOK TROUT      1526\n",
            "BROWN TROUT       330\n",
            "L.L. SALMON       200\n",
            "LAKE TROUT         11\n",
            "NORTHENR PIKE       1\n",
            "NORTHERN PIKE      29\n",
            "RAINBOW TROUT      80\n",
            "SPLAKE             60\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Columns: ['COUNTY', 'DATE', 'WATER', 'TOWN', 'SPECIES', 'QTY', 'SIZE (inch)', 'X_coord', 'Y_coord', 'ABUNDANCE']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/pm/v1wywnps12sf4vmw4zxrydwr0000gn/T/ipykernel_64046/4010754209.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_updated_new = pd.concat([df_2025_final, permanent_data], ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COUNTY</th>\n",
              "      <th>DATE</th>\n",
              "      <th>WATER</th>\n",
              "      <th>TOWN</th>\n",
              "      <th>SPECIES</th>\n",
              "      <th>QTY</th>\n",
              "      <th>SIZE (inch)</th>\n",
              "      <th>X_coord</th>\n",
              "      <th>Y_coord</th>\n",
              "      <th>ABUNDANCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>2025-02-11</td>\n",
              "      <td>RANGE P (LOWER)</td>\n",
              "      <td>Poland</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>300</td>\n",
              "      <td>14</td>\n",
              "      <td>-70.369148</td>\n",
              "      <td>44.043731</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cumberland</td>\n",
              "      <td>2025-04-03</td>\n",
              "      <td>SONGO R</td>\n",
              "      <td>Casco</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>100</td>\n",
              "      <td>16</td>\n",
              "      <td>-70.574503</td>\n",
              "      <td>43.930731</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cumberland</td>\n",
              "      <td>2025-04-03</td>\n",
              "      <td>JORDAN R</td>\n",
              "      <td>Raymond</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>100</td>\n",
              "      <td>16</td>\n",
              "      <td>-70.462052</td>\n",
              "      <td>43.896887</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cumberland</td>\n",
              "      <td>2025-04-03</td>\n",
              "      <td>PRESUMPSCOT R</td>\n",
              "      <td>Windham</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>200</td>\n",
              "      <td>16</td>\n",
              "      <td>-70.410724</td>\n",
              "      <td>43.717251</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cumberland</td>\n",
              "      <td>2025-04-07</td>\n",
              "      <td>COLLYER B</td>\n",
              "      <td>Gray</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>-70.302713</td>\n",
              "      <td>43.905907</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         COUNTY       DATE            WATER     TOWN      SPECIES  QTY  \\\n",
              "0  Androscoggin 2025-02-11  RANGE P (LOWER)   Poland  BROOK TROUT  300   \n",
              "1    Cumberland 2025-04-03          SONGO R    Casco  BROOK TROUT  100   \n",
              "2    Cumberland 2025-04-03         JORDAN R  Raymond  BROOK TROUT  100   \n",
              "3    Cumberland 2025-04-03    PRESUMPSCOT R  Windham  BROOK TROUT  200   \n",
              "4    Cumberland 2025-04-07        COLLYER B     Gray  BROOK TROUT  100   \n",
              "\n",
              "   SIZE (inch)    X_coord    Y_coord ABUNDANCE  \n",
              "0           14 -70.369148  44.043731      None  \n",
              "1           16 -70.574503  43.930731      None  \n",
              "2           16 -70.462052  43.896887      None  \n",
              "3           16 -70.410724  43.717251      None  \n",
              "4           10 -70.302713  43.905907      None  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combine 2025 data with permanent species data\n",
        "# Ensure both have same columns (add ABUNDANCE column for char data)\n",
        "df_2025_final['ABUNDANCE'] = None\n",
        "\n",
        "# Ensure column order matches\n",
        "column_order = ['COUNTY', 'DATE', 'WATER', 'TOWN', 'SPECIES', 'QTY', 'SIZE (inch)', 'X_coord', 'Y_coord', 'ABUNDANCE']\n",
        "df_2025_final = df_2025_final[column_order]\n",
        "permanent_data = permanent_data[column_order]\n",
        "\n",
        "# Combine dataframes\n",
        "df_updated_new = pd.concat([df_2025_final, permanent_data], ignore_index=True)\n",
        "\n",
        "print(f\"Combined dataset: {len(df_updated_new)} rows\")\n",
        "print(f\"\\nSpecies breakdown:\")\n",
        "print(df_updated_new['SPECIES'].value_counts().sort_index())\n",
        "print(f\"\\nColumns: {df_updated_new.columns.tolist()}\")\n",
        "df_updated_new.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coordinate reference: 957 unique locations\n",
            "\n",
            "Columns: ['WATER', 'TOWN', 'COUNTY', 'X_coord', 'Y_coord']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WATER</th>\n",
              "      <th>TOWN</th>\n",
              "      <th>COUNTY</th>\n",
              "      <th>X_coord</th>\n",
              "      <th>Y_coord</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ANDROSCOGGIN R (LITTLE)</td>\n",
              "      <td>Auburn</td>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>-70.239381</td>\n",
              "      <td>44.071433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AUBURN L</td>\n",
              "      <td>Auburn</td>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>-70.253311</td>\n",
              "      <td>44.144799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BASIN B</td>\n",
              "      <td>Auburn</td>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>-70.286303</td>\n",
              "      <td>44.184689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PETTINGILL PARK P</td>\n",
              "      <td>Auburn</td>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>-70.234543</td>\n",
              "      <td>44.106918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ROYAL R</td>\n",
              "      <td>Auburn</td>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>-70.260466</td>\n",
              "      <td>44.006769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TAYLOR P</td>\n",
              "      <td>Auburn</td>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>-70.278494</td>\n",
              "      <td>44.109052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MEADOW B</td>\n",
              "      <td>Durham</td>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>-70.069211</td>\n",
              "      <td>43.975001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NEWELL B</td>\n",
              "      <td>Durham</td>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>-70.1009</td>\n",
              "      <td>43.98565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SABATTUS P (LITTLE)</td>\n",
              "      <td>Greene</td>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>-70.134896</td>\n",
              "      <td>44.210982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>STETSON B</td>\n",
              "      <td>Lewiston</td>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>-69.123939</td>\n",
              "      <td>44.838304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     WATER      TOWN        COUNTY    X_coord    Y_coord\n",
              "0  ANDROSCOGGIN R (LITTLE)    Auburn  Androscoggin -70.239381  44.071433\n",
              "1                 AUBURN L    Auburn  Androscoggin -70.253311  44.144799\n",
              "2                  BASIN B    Auburn  Androscoggin -70.286303  44.184689\n",
              "3        PETTINGILL PARK P    Auburn  Androscoggin -70.234543  44.106918\n",
              "4                  ROYAL R    Auburn  Androscoggin -70.260466  44.006769\n",
              "5                 TAYLOR P    Auburn  Androscoggin -70.278494  44.109052\n",
              "6                 MEADOW B    Durham  Androscoggin -70.069211  43.975001\n",
              "7                 NEWELL B    Durham  Androscoggin   -70.1009   43.98565\n",
              "8      SABATTUS P (LITTLE)    Greene  Androscoggin -70.134896  44.210982\n",
              "9                STETSON B  Lewiston  Androscoggin -69.123939  44.838304"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create coordinate reference file with all unique coordinates\n",
        "# Columns: WATER, TOWN, COUNTY, X_coord, Y_coord\n",
        "coord_reference = df_updated_new[\n",
        "    df_updated_new['X_coord'].notna() & df_updated_new['Y_coord'].notna()\n",
        "][['WATER', 'TOWN', 'COUNTY', 'X_coord', 'Y_coord']].drop_duplicates(\n",
        "    subset=['WATER', 'TOWN', 'COUNTY']\n",
        ").sort_values(['COUNTY', 'TOWN', 'WATER']).reset_index(drop=True)\n",
        "\n",
        "print(f\"Coordinate reference: {len(coord_reference)} unique locations\")\n",
        "print(f\"\\nColumns: {coord_reference.columns.tolist()}\")\n",
        "coord_reference.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving files...\n",
            "✅ Saved df_updated.csv with 2251 rows\n",
            "✅ Saved coordinate_reference.csv with 957 unique locations\n",
            "\n",
            "================================================================================\n",
            "UPDATE COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "Summary:\n",
            "  Total rows in df_updated.csv: 2251\n",
            "  Unique locations with coordinates: 957\n",
            "  2025 stocked species rows: 2207\n",
            "  Permanent species rows: 44\n"
          ]
        }
      ],
      "source": [
        "# Save updated data\n",
        "print(\"Saving files...\")\n",
        "\n",
        "# Save df_updated.csv\n",
        "df_updated_new.to_csv('df_updated.csv', index=False)\n",
        "print(f\"✅ Saved df_updated.csv with {len(df_updated_new)} rows\")\n",
        "\n",
        "# Save coordinate_reference.csv\n",
        "coord_reference.to_csv('coordinate_reference.csv', index=False)\n",
        "print(f\"✅ Saved coordinate_reference.csv with {len(coord_reference)} unique locations\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"UPDATE COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Total rows in df_updated.csv: {len(df_updated_new)}\")\n",
        "print(f\"  Unique locations with coordinates: {len(coord_reference)}\")\n",
        "print(f\"  2025 stocked species rows: {len(df_2025_final)}\")\n",
        "print(f\"  Permanent species rows: {len(permanent_data)}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
