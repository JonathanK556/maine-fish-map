{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explore 2025 Stocking Data\n",
        "\n",
        "This notebook explores the new 2025 stocking data and identifies:\n",
        "- Bodies of water that are new (not in existing 2024 data)\n",
        "- Bodies of water that are missing coordinates\n",
        "- Differences between 2024 and 2025 data\n",
        "\n",
        "**Goal:** Prepare for updating the map with 2025 data while preserving pike and char data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025 Data Shape: (2207, 21)\n",
            "\n",
            "Columns: ['Id', 'WATCODE', 'WATER', 'TOWN', 'COUNTY', 'REGION', 'SPP', 'STRAIN', 'AGEGRP', 'QTYRequested', 'QTYDelivered', 'KGs', 'mm', 'Inches', 'MARKS', 'DeliveryDate', 'HATCHERY', 'ORDER TYPE', 'SITE', 'COMMENTS', 'NOTE']\n",
            "\n",
            "First few rows:\n",
            "\n",
            "Data types:\n",
            "Id                       int64\n",
            "WATCODE                 object\n",
            "WATER                   object\n",
            "TOWN                    object\n",
            "COUNTY                  object\n",
            "REGION                  object\n",
            "SPP                     object\n",
            "STRAIN                   int64\n",
            "AGEGRP                  object\n",
            "QTYRequested             int64\n",
            "QTYDelivered             int64\n",
            "KGs                    float64\n",
            "mm                       int64\n",
            "Inches                   int64\n",
            "MARKS                   object\n",
            "DeliveryDate    datetime64[ns]\n",
            "HATCHERY                object\n",
            "ORDER TYPE              object\n",
            "SITE                    object\n",
            "COMMENTS                object\n",
            "NOTE                    object\n",
            "dtype: object\n",
            "\n",
            "Sample values from each column:\n",
            "\n",
            "Id: [46266 50951 50952 50950 47177 47176 47186 47178 46686 46645]\n",
            "\n",
            "WATCODE: ['3760' '043031' '043034' '043' '046009' '04600901' '020' '00801408' '019'\n",
            " '016']\n",
            "\n",
            "WATER: ['RANGE P (LOWER)' 'SONGO R' 'JORDAN R' 'PRESUMPSCOT R' 'COLLYER B'\n",
            " 'BRANDY B' 'OGUNQUIT R' 'WORSTER B' 'JOSIAS R' 'CAPE NEDDICK R']\n",
            "\n",
            "TOWN: ['Poland' 'Casco' 'Raymond' 'Windham' 'Gray' 'New Gloucester' 'Wells'\n",
            " 'Berwick' 'York' 'Kennebunkport']\n",
            "\n",
            "COUNTY: ['Androscoggin' 'Cumberland' 'York' 'Oxford' 'Sagadahoc' 'Penobscot'\n",
            " 'Somerset' 'Kennebec' 'Lincoln' 'Knox']\n",
            "\n",
            "REGION: ['A' 'B' 'C' 'D' 'E' 'F' 'G']\n",
            "\n",
            "SPP: ['BKT' 'SPK' 'BNT' 'RBT' 'LKT' 'LLS']\n",
            "\n",
            "STRAIN: [21 38 79 43 81 64 67 10 51 53]\n",
            "\n",
            "AGEGRP: ['AY' 'SY' 'FRY' 'FF' 'AFF' 'FY' 'AD']\n",
            "\n",
            "QTYRequested: [300 100 200  75 150 500 350 125 800 225]\n",
            "\n",
            "QTYDelivered: [300 100 200  75 150 500 350 125 800 225]\n",
            "\n",
            "KGs: [150.  70. 140.  17.  13.  25.  34.  84.  43.  65.]\n",
            "\n",
            "mm: [350 402 250 260 266 228 240 258 235 255]\n",
            "\n",
            "Inches: [14 16 10  9  8 11  2  6  7 15]\n",
            "\n",
            "MARKS: [nan 'AD' 'RVAD' 'RV' 'BV' 'LVAD' 'LV' 'LP' 'LPAD']\n",
            "\n",
            "DeliveryDate: <DatetimeArray>\n",
            "['2025-02-11 00:00:00', '2025-04-03 00:00:00', '2025-04-07 00:00:00',\n",
            " '2025-04-08 00:00:00', '2025-04-10 00:00:00', '2025-04-11 00:00:00',\n",
            " '2025-04-15 00:00:00', '2025-04-16 00:00:00', '2025-04-17 00:00:00',\n",
            " '2025-04-18 00:00:00']\n",
            "Length: 10, dtype: datetime64[ns]\n",
            "\n",
            "HATCHERY: ['DRY MILLS' 'GOV HILL' 'CASCO' 'NEW GLST' 'ENFIELD' 'EMBDEN' 'PALERMO'\n",
            " 'GRAND LAKE' 'DEAD RIVER']\n",
            "\n",
            "ORDER TYPE: ['Scheduled' 'Unscheduled' 'Add Change' 'Legislative']\n",
            "\n",
            "SITE: ['STATE PARK' 'BELOW LOCKS' 'BELOW PANTHER RUN DAM OFF MILL ST.'\n",
            " 'RTE. 35 XING' 'MERRILL RD. XING' 'MEGUIRE RD. XING' 'MORSE RD. XING'\n",
            " 'RTE. 100 XING' 'CAPTAIN THOMAS RD. XING' 'RTE. 236 XING']\n",
            "\n",
            "COMMENTS: ['MDIFW R3 EVENT - COORDINATE W/ CHELSEA' 'UNSCHEDULED' 'LATE APRIL' nan\n",
            " 'EARLY APRIL' 'GATED - CONTACT CHRIS SHAW @ 329-4225' 'MID APRIL'\n",
            " 'CONTACT NORM LAMBERT @ 432-7706 TO MOVE ROCKS'\n",
            " 'GATE - CONTACT SHAWN DOUGHTY @ 603-770-4871 or 603-294-5146'\n",
            " 'LATE APRIL; NEW SITE']\n",
            "\n",
            "NOTE: ['Cancelled order, then reinstated with extra males for Extravaganza'\n",
            " 'Added per Reg. A' nan 'Added 75 per Reg. A'\n",
            " 'Switched from FY to SY - Due to NG shutdown' 'Collateral triploids'\n",
            " 'Removed Derby Comments'\n",
            " 'Switched to SY program, Ameneded for triploid study per Reg. A'\n",
            " 'Amended for triploid study per Reg. A' 'Amended info per Reg. A']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jonathan/Library/Python/3.9/lib/python/site-packages/openpyxl/worksheet/header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
            "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
          ]
        }
      ],
      "source": [
        "# Load 2025 stocking data\n",
        "df_2025 = pd.read_excel('2025_Stocking.xlsx')\n",
        "\n",
        "print(f\"2025 Data Shape: {df_2025.shape}\")\n",
        "print(f\"\\nColumns: {df_2025.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_2025.head()\n",
        "\n",
        "# Show data types and sample values\n",
        "print(f\"\\nData types:\")\n",
        "print(df_2025.dtypes)\n",
        "print(f\"\\nSample values from each column:\")\n",
        "for col in df_2025.columns:\n",
        "    print(f\"\\n{col}: {df_2025[col].unique()[:10]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Data Shape: (1232, 10)\n",
            "\n",
            "Columns: ['COUNTY', 'DATE', 'WATER', 'TOWN', 'SPECIES', 'QTY', 'SIZE (inch)', 'X_coord', 'Y_coord', 'ABUNDANCE']\n",
            "\n",
            "Unique species in current data: ['ARCTIC CHAR', 'BROOK TROUT', 'BROWN TROUT', 'L.L. SALMON', 'LAKE TROUT', 'NORTHERN PIKE', 'RAINBOW TROUT', 'SPLAKE']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COUNTY</th>\n",
              "      <th>DATE</th>\n",
              "      <th>WATER</th>\n",
              "      <th>TOWN</th>\n",
              "      <th>SPECIES</th>\n",
              "      <th>QTY</th>\n",
              "      <th>SIZE (inch)</th>\n",
              "      <th>X_coord</th>\n",
              "      <th>Y_coord</th>\n",
              "      <th>ABUNDANCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>2024-01-23</td>\n",
              "      <td>RANGE P (MIDDLE)</td>\n",
              "      <td>Poland</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>100.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-70.379485</td>\n",
              "      <td>44.026658</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>2024-02-15</td>\n",
              "      <td>RANGE P (LOWER)</td>\n",
              "      <td>Poland</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>300.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-70.369148</td>\n",
              "      <td>44.043731</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>2024-04-02</td>\n",
              "      <td>WORTHLEY P</td>\n",
              "      <td>Poland</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>200.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-70.344777</td>\n",
              "      <td>44.018762</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>2024-04-11</td>\n",
              "      <td>BARTLETT P</td>\n",
              "      <td>Livermore</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>440.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-70.205208</td>\n",
              "      <td>44.401191</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Androscoggin</td>\n",
              "      <td>2024-04-11</td>\n",
              "      <td>BRETTUNS P</td>\n",
              "      <td>Livermore</td>\n",
              "      <td>BROOK TROUT</td>\n",
              "      <td>300.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-70.250268</td>\n",
              "      <td>44.392663</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         COUNTY        DATE             WATER       TOWN      SPECIES    QTY  \\\n",
              "0  Androscoggin  2024-01-23  RANGE P (MIDDLE)     Poland  BROOK TROUT  100.0   \n",
              "1  Androscoggin  2024-02-15   RANGE P (LOWER)     Poland  BROOK TROUT  300.0   \n",
              "2  Androscoggin  2024-04-02        WORTHLEY P     Poland  BROOK TROUT  200.0   \n",
              "3  Androscoggin  2024-04-11        BARTLETT P  Livermore  BROOK TROUT  440.0   \n",
              "4  Androscoggin  2024-04-11        BRETTUNS P  Livermore  BROOK TROUT  300.0   \n",
              "\n",
              "   SIZE (inch)    X_coord    Y_coord ABUNDANCE  \n",
              "0         14.0 -70.379485  44.026658       NaN  \n",
              "1         14.0 -70.369148  44.043731       NaN  \n",
              "2         10.0 -70.344777  44.018762       NaN  \n",
              "3         10.0 -70.205208  44.401191       NaN  \n",
              "4         10.0 -70.250268  44.392663       NaN  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load existing combined data\n",
        "df_current = pd.read_csv('df_updated.csv')\n",
        "\n",
        "print(f\"Current Data Shape: {df_current.shape}\")\n",
        "print(f\"\\nColumns: {df_current.columns.tolist()}\")\n",
        "print(f\"\\nUnique species in current data: {sorted(df_current['SPECIES'].unique())}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_current.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standardized columns in 2025 data:\n",
            "['TOWN', 'DATE', 'WATER', 'COUNTY', 'SPECIES', 'QTY', 'SIZE (inch)']\n",
            "\n",
            "Species codes found and mapped:\n",
            "Unique species values: ['BROOK TROUT', 'BROWN TROUT', 'L.L. SALMON', 'LAKE TROUT', 'RAINBOW TROUT', 'SPLAKE']\n",
            "\n",
            "Data shape: (2207, 7)\n",
            "\n",
            "First few rows after standardization:\n"
          ]
        }
      ],
      "source": [
        "# Standardize 2025 data - we need: TOWN, DATE, WATER, COUNTY, SPECIES, QTY, SIZE (inch)\n",
        "# First normalize column names to uppercase\n",
        "df_2025.columns = df_2025.columns.str.strip().str.upper()\n",
        "\n",
        "# Map actual column names to standard names based on what we see in the data\n",
        "# From the output: DELIVERYDATE -> DATE, INCHES -> SIZE (inch), QTYDELIVERED -> QTY, SPP -> SPECIES\n",
        "column_mapping = {\n",
        "    'DELIVERYDATE': 'DATE',\n",
        "    'DATE': 'DATE',  # Keep if already named correctly\n",
        "    'INCHES': 'SIZE (inch)',\n",
        "    'QTYDELIVERED': 'QTY',  # Use delivered quantity\n",
        "    'QTYREQUESTED': 'QTY',  # Fallback to requested if delivered not available\n",
        "    'QUANTITY': 'QTY',\n",
        "    'SPP': 'SPECIES',  # Species code column\n",
        "    'SPECIES': 'SPECIES'  # Keep if already named correctly\n",
        "}\n",
        "\n",
        "# Rename columns based on mapping (prioritize first match)\n",
        "for old_name, new_name in column_mapping.items():\n",
        "    if old_name in df_2025.columns:\n",
        "        if new_name not in df_2025.columns or old_name == new_name:\n",
        "            df_2025 = df_2025.rename(columns={old_name: new_name})\n",
        "\n",
        "# Handle QTY - use QTYDELIVERED if available, otherwise QTYREQUESTED\n",
        "if 'QTYDELIVERED' in df_2025.columns and 'QTY' not in df_2025.columns:\n",
        "    df_2025['QTY'] = df_2025['QTYDELIVERED']\n",
        "elif 'QTYREQUESTED' in df_2025.columns and 'QTY' not in df_2025.columns:\n",
        "    df_2025['QTY'] = df_2025['QTYREQUESTED']\n",
        "\n",
        "# Map species codes to full species names\n",
        "# BKT = brook trout, RBT = rainbow trout, LKT = lake trout, \n",
        "# BNT = brown trout, LLS = landlocked salmon, SPK = splake\n",
        "species_code_mapping = {\n",
        "    'BKT': 'BROOK TROUT',\n",
        "    'RBT': 'RAINBOW TROUT',\n",
        "    'LKT': 'LAKE TROUT',\n",
        "    'BNT': 'BROWN TROUT',\n",
        "    'LLS': 'L.L. SALMON',\n",
        "    'SPK': 'SPLAKE'\n",
        "}\n",
        "\n",
        "# Convert species codes to full names\n",
        "if 'SPECIES' in df_2025.columns:\n",
        "    df_2025['SPECIES'] = df_2025['SPECIES'].str.strip().str.upper().map(\n",
        "        lambda x: species_code_mapping.get(x, x) if pd.notna(x) else x\n",
        "    )\n",
        "\n",
        "# Select only the columns we need: TOWN, DATE, WATER, COUNTY, SPECIES, QTY, SIZE (inch)\n",
        "required_columns = ['TOWN', 'DATE', 'WATER', 'COUNTY', 'SPECIES', 'QTY', 'SIZE (inch)']\n",
        "available_columns = [col for col in required_columns if col in df_2025.columns]\n",
        "\n",
        "# Keep only required columns\n",
        "df_2025_clean = df_2025[available_columns].copy()\n",
        "\n",
        "# Add missing columns as None if they don't exist\n",
        "for col in required_columns:\n",
        "    if col not in df_2025_clean.columns:\n",
        "        df_2025_clean[col] = None\n",
        "        print(f\"Warning: Column '{col}' not found in 2025 data - added as None\")\n",
        "\n",
        "# Reorder columns to match required order\n",
        "df_2025_clean = df_2025_clean[required_columns]\n",
        "\n",
        "print(\"Standardized columns in 2025 data:\")\n",
        "print(df_2025_clean.columns.tolist())\n",
        "print(f\"\\nSpecies codes found and mapped:\")\n",
        "print(f\"Unique species values: {sorted(df_2025_clean['SPECIES'].dropna().unique())}\")\n",
        "print(f\"\\nData shape: {df_2025_clean.shape}\")\n",
        "print(f\"\\nFirst few rows after standardization:\")\n",
        "df_2025_clean.head()\n",
        "\n",
        "# Use the clean dataframe going forward\n",
        "df_2025 = df_2025_clean.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current stocked species data rows: 1189\n",
            "\n",
            "Species in current stocked data: ['BROOK TROUT', 'BROWN TROUT', 'L.L. SALMON', 'LAKE TROUT', 'RAINBOW TROUT', 'SPLAKE']\n",
            "\n",
            "Permanent species data rows: 43\n",
            "Species in permanent data: ['ARCTIC CHAR', 'NORTHERN PIKE']\n"
          ]
        }
      ],
      "source": [
        "# Extract only stocked species from current data (exclude pike and char for now)\n",
        "# These are permanent species that we'll keep\n",
        "permanent_species = ['NORTHERN PIKE', 'ARCTIC CHAR']\n",
        "\n",
        "# Get current stocked species data (trout, salmon, splake - these will be replaced)\n",
        "current_stocked = df_current[~df_current['SPECIES'].isin(permanent_species)].copy()\n",
        "\n",
        "print(f\"Current stocked species data rows: {len(current_stocked)}\")\n",
        "print(f\"\\nSpecies in current stocked data: {sorted(current_stocked['SPECIES'].unique())}\")\n",
        "\n",
        "# Get permanent species data (pike and char - these we'll keep)\n",
        "permanent_data = df_current[df_current['SPECIES'].isin(permanent_species)].copy()\n",
        "print(f\"\\nPermanent species data rows: {len(permanent_data)}\")\n",
        "print(f\"Species in permanent data: {sorted(permanent_data['SPECIES'].unique())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found coordinates for 951 unique waterbody/town combinations\n",
            "\n",
            "Sample of coordinate lookup (first 5):\n",
            "  RANGE P (MIDDLE), POLAND: (-70.379485, 44.026658)\n",
            "  RANGE P (LOWER), POLAND: (-70.369148, 44.043731)\n",
            "  WORTHLEY P, POLAND: (-70.344777, 44.018762)\n",
            "  BARTLETT P, LIVERMORE: (-70.205208, 44.401191)\n",
            "  BRETTUNS P, LIVERMORE: (-70.250268, 44.392663)\n"
          ]
        }
      ],
      "source": [
        "# Create a coordinate lookup from current data\n",
        "# Key: (WATER, TOWN) tuple, Value: (X_coord, Y_coord) tuple\n",
        "coord_lookup = {}\n",
        "\n",
        "for _, row in df_current.iterrows():\n",
        "    if pd.notna(row['X_coord']) and pd.notna(row['Y_coord']):\n",
        "        key = (str(row['WATER']).strip().upper(), str(row['TOWN']).strip().upper())\n",
        "        coord_lookup[key] = (float(row['X_coord']), float(row['Y_coord']))\n",
        "\n",
        "print(f\"Found coordinates for {len(coord_lookup)} unique waterbody/town combinations\")\n",
        "print(f\"\\nSample of coordinate lookup (first 5):\")\n",
        "for i, (key, coords) in enumerate(list(coord_lookup.items())[:5]):\n",
        "    print(f\"  {key[0]}, {key[1]}: ({coords[0]:.6f}, {coords[1]:.6f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique waterbody/town combinations in 2025 data: 921\n",
            "\n",
            "Total rows in 2025 data: 2207\n",
            "\n",
            "Species in 2025 data: ['BROOK TROUT', 'BROWN TROUT', 'L.L. SALMON', 'LAKE TROUT', 'RAINBOW TROUT', 'SPLAKE']\n",
            "\n",
            "Columns in 2025 data: ['TOWN', 'DATE', 'WATER', 'COUNTY', 'SPECIES', 'QTY', 'SIZE (inch)', 'X_coord', 'Y_coord', 'key']\n"
          ]
        }
      ],
      "source": [
        "# Prepare 2025 data for analysis\n",
        "# Add empty coordinate columns (will be filled from existing data or left blank)\n",
        "df_2025_prep = df_2025.copy()\n",
        "df_2025_prep['X_coord'] = None\n",
        "df_2025_prep['Y_coord'] = None\n",
        "\n",
        "# Create standardized keys for matching (WATER, TOWN)\n",
        "df_2025_prep['key'] = df_2025_prep.apply(\n",
        "    lambda row: (str(row['WATER']).strip().upper(), str(row['TOWN']).strip().upper()), \n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Check unique waterbodies in 2025 data\n",
        "unique_2025_locations = df_2025_prep[['WATER', 'TOWN', 'COUNTY']].drop_duplicates()\n",
        "print(f\"Unique waterbody/town combinations in 2025 data: {len(unique_2025_locations)}\")\n",
        "print(f\"\\nTotal rows in 2025 data: {len(df_2025_prep)}\")\n",
        "print(f\"\\nSpecies in 2025 data: {sorted(df_2025_prep['SPECIES'].dropna().unique())}\")\n",
        "print(f\"\\nColumns in 2025 data: {df_2025_prep.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waterbodies WITH coordinates: 2189 rows\n",
            "Waterbodies MISSING coordinates: 18 rows\n",
            "\n",
            "Unique waterbody/town combinations MISSING coordinates: 14\n",
            "\n",
            "Unique waterbody/town combinations WITH coordinates: 908\n"
          ]
        }
      ],
      "source": [
        "# Identify which 2025 waterbodies have coordinates and which don't\n",
        "df_2025_prep['has_coords'] = df_2025_prep['key'].apply(\n",
        "    lambda k: k in coord_lookup\n",
        ")\n",
        "\n",
        "# For those with coordinates, populate them\n",
        "for idx, row in df_2025_prep.iterrows():\n",
        "    if row['has_coords']:\n",
        "        coords = coord_lookup[row['key']]\n",
        "        df_2025_prep.at[idx, 'X_coord'] = coords[0]\n",
        "        df_2025_prep.at[idx, 'Y_coord'] = coords[1]\n",
        "\n",
        "# Get unique locations that are missing coordinates\n",
        "missing_coords = df_2025_prep[~df_2025_prep['has_coords']][['WATER', 'TOWN', 'COUNTY', 'SPECIES']].drop_duplicates()\n",
        "\n",
        "print(f\"Waterbodies WITH coordinates: {df_2025_prep['has_coords'].sum()} rows\")\n",
        "print(f\"Waterbodies MISSING coordinates: {(~df_2025_prep['has_coords']).sum()} rows\")\n",
        "print(f\"\\nUnique waterbody/town combinations MISSING coordinates: {len(missing_coords)}\")\n",
        "print(f\"\\nUnique waterbody/town combinations WITH coordinates: {df_2025_prep[df_2025_prep['has_coords']][['WATER', 'TOWN']].drop_duplicates().shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "LOCATIONS MISSING COORDINATES\n",
            "================================================================================\n",
            "\n",
            "Total unique locations missing coordinates: 14\n",
            "\n",
            "                         WATER                  TOWN     COUNTY     SPECIES\n",
            "            MUSQUACOOK L (2ND)          T11 R11 WELS  Aroostook  LAKE TROUT\n",
            "                    UMSASKIS L          T11 R13 WELS  Aroostook  LAKE TROUT\n",
            "               NICATOUS STREAM                 T3 ND    Hancock BROOK TROUT\n",
            "                       BASIN P               Fayette   Kennebec BROOK TROUT\n",
            "                       BASIN P               Fayette   Kennebec      SPLAKE\n",
            "                      DENNIS B            Litchfield   Kennebec BROOK TROUT\n",
            "                     POTTERS B            Litchfield   Kennebec BROOK TROUT\n",
            "                       FRESH P           North Haven       Knox BROOK TROUT\n",
            "BANGOR MUNICIPAL GOLF COURSE P                Bangor  Penobscot BROOK TROUT\n",
            "                       MOORE P        Bradstreet Twp   Somerset BROOK TROUT\n",
            "                     KNIGHTS P        Squaretown Twp   Somerset BROOK TROUT\n",
            "                         BIG L Grand Lake Stream Plt Washington L.L. SALMON\n",
            "                      BOYDEN L                 Perry Washington L.L. SALMON\n",
            "           SPECTACLE L (UPPER)            T19 ED BPP Washington BROOK TROUT\n"
          ]
        }
      ],
      "source": [
        "# Show locations missing coordinates (sorted by county, town, water)\n",
        "print(\"=\" * 80)\n",
        "print(\"LOCATIONS MISSING COORDINATES\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nTotal unique locations missing coordinates: {len(missing_coords)}\\n\")\n",
        "\n",
        "missing_coords_sorted = missing_coords.sort_values(['COUNTY', 'TOWN', 'WATER'])\n",
        "print(missing_coords_sorted.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "COMPARISON: 2024 vs 2025\n",
            "================================================================================\n",
            "\n",
            "Unique locations in 2024 data: 916\n",
            "Unique locations in 2025 data: 921\n",
            "\n",
            "NEW locations in 2025 (not in 2024): 13\n",
            "REMOVED locations from 2024 (not in 2025): 8\n",
            "Locations in BOTH: 908\n"
          ]
        }
      ],
      "source": [
        "# Compare with 2024 data to identify NEW waterbodies\n",
        "# Get unique locations from 2024 stocked data\n",
        "unique_2024_locations = current_stocked[['WATER', 'TOWN', 'COUNTY']].drop_duplicates()\n",
        "unique_2024_locations['key'] = unique_2024_locations.apply(\n",
        "    lambda row: (str(row['WATER']).strip().upper(), str(row['TOWN']).strip().upper()),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Get unique locations from 2025 data\n",
        "unique_2025_locations_clean = df_2025_prep[['WATER', 'TOWN', 'COUNTY']].drop_duplicates()\n",
        "unique_2025_locations_clean['key'] = unique_2025_locations_clean.apply(\n",
        "    lambda row: (str(row['WATER']).strip().upper(), str(row['TOWN']).strip().upper()),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Find new locations in 2025\n",
        "set_2024 = set(unique_2024_locations['key'].tolist())\n",
        "set_2025 = set(unique_2025_locations_clean['key'].tolist())\n",
        "\n",
        "new_locations = set_2025 - set_2024\n",
        "removed_locations = set_2024 - set_2025\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"COMPARISON: 2024 vs 2025\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nUnique locations in 2024 data: {len(set_2024)}\")\n",
        "print(f\"Unique locations in 2025 data: {len(set_2025)}\")\n",
        "print(f\"\\nNEW locations in 2025 (not in 2024): {len(new_locations)}\")\n",
        "print(f\"REMOVED locations from 2024 (not in 2025): {len(removed_locations)}\")\n",
        "print(f\"Locations in BOTH: {len(set_2024 & set_2025)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "NEW LOCATIONS IN 2025 (not present in 2024)\n",
            "================================================================================\n",
            "\n",
            "Total new locations: 13\n",
            "\n",
            "                         WATER                  TOWN     COUNTY\n",
            "            MUSQUACOOK L (2ND)          T11 R11 WELS  Aroostook\n",
            "                    UMSASKIS L          T11 R13 WELS  Aroostook\n",
            "               NICATOUS STREAM                 T3 ND    Hancock\n",
            "                       BASIN P               Fayette   Kennebec\n",
            "                      DENNIS B            Litchfield   Kennebec\n",
            "                     POTTERS B            Litchfield   Kennebec\n",
            "                       FRESH P           North Haven       Knox\n",
            "BANGOR MUNICIPAL GOLF COURSE P                Bangor  Penobscot\n",
            "                       MOORE P        Bradstreet Twp   Somerset\n",
            "                     KNIGHTS P        Squaretown Twp   Somerset\n",
            "                         BIG L Grand Lake Stream Plt Washington\n",
            "                      BOYDEN L                 Perry Washington\n",
            "           SPECTACLE L (UPPER)            T19 ED BPP Washington\n"
          ]
        }
      ],
      "source": [
        "# Show new locations in 2025\n",
        "if len(new_locations) > 0:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"NEW LOCATIONS IN 2025 (not present in 2024)\")\n",
        "    print(\"=\" * 80)\n",
        "    new_locations_df = unique_2025_locations_clean[\n",
        "        unique_2025_locations_clean['key'].isin(new_locations)\n",
        "    ][['WATER', 'TOWN', 'COUNTY']].sort_values(['COUNTY', 'TOWN', 'WATER'])\n",
        "    print(f\"\\nTotal new locations: {len(new_locations_df)}\\n\")\n",
        "    print(new_locations_df.to_string(index=False))\n",
        "else:\n",
        "    print(\"\\nNo new locations found in 2025 data.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "LOCATIONS REMOVED FROM 2024 (not present in 2025)\n",
            "================================================================================\n",
            "\n",
            "Total removed locations: 8\n",
            "\n",
            "                       WATER            TOWN      COUNTY\n",
            "                     BROWN P         Houlton   Aroostook\n",
            "               SCOPAN STREAM        Masardis   Aroostook\n",
            "PORTAGE HILLS COUNTRY CLUB P    Portage Lake   Aroostook\n",
            "                  MOCCASIN P     T14 R8 WELS   Aroostook\n",
            "                      B POND           Upton      Oxford\n",
            "            ROACH P (FOURTH)    Shawtown Twp Piscataquis\n",
            "          PARADISE P (UPPER) Parlin Pond Twp    Somerset\n",
            "                   PATRICK L      Marion Twp  Washington\n"
          ]
        }
      ],
      "source": [
        "# Show removed locations (in 2024 but not in 2025)\n",
        "if len(removed_locations) > 0:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"LOCATIONS REMOVED FROM 2024 (not present in 2025)\")\n",
        "    print(\"=\" * 80)\n",
        "    removed_locations_df = unique_2024_locations[\n",
        "        unique_2024_locations['key'].isin(removed_locations)\n",
        "    ][['WATER', 'TOWN', 'COUNTY']].sort_values(['COUNTY', 'TOWN', 'WATER'])\n",
        "    print(f\"\\nTotal removed locations: {len(removed_locations_df)}\\n\")\n",
        "    print(removed_locations_df.to_string(index=False))\n",
        "else:\n",
        "    print(\"\\nNo locations were removed (all 2024 locations appear in 2025).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SUMMARY: Locations Missing Coordinates\n",
            "================================================================================\n",
            "\n",
            "Total unique locations missing coordinates: 13\n",
            "\n",
            "Breakdown by county:\n",
            "COUNTY\n",
            "Kennebec      3\n",
            "Washington    3\n",
            "Aroostook     2\n",
            "Somerset      2\n",
            "Hancock       1\n",
            "Knox          1\n",
            "Penobscot     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "First 20 locations (full list below):\n",
            "                         WATER                  TOWN     COUNTY X_coord Y_coord\n",
            "            MUSQUACOOK L (2ND)          T11 R11 WELS  Aroostook    None    None\n",
            "                    UMSASKIS L          T11 R13 WELS  Aroostook    None    None\n",
            "               NICATOUS STREAM                 T3 ND    Hancock    None    None\n",
            "                       BASIN P               Fayette   Kennebec    None    None\n",
            "                      DENNIS B            Litchfield   Kennebec    None    None\n",
            "                     POTTERS B            Litchfield   Kennebec    None    None\n",
            "                       FRESH P           North Haven       Knox    None    None\n",
            "BANGOR MUNICIPAL GOLF COURSE P                Bangor  Penobscot    None    None\n",
            "                       MOORE P        Bradstreet Twp   Somerset    None    None\n",
            "                     KNIGHTS P        Squaretown Twp   Somerset    None    None\n",
            "                         BIG L Grand Lake Stream Plt Washington    None    None\n",
            "                      BOYDEN L                 Perry Washington    None    None\n",
            "           SPECTACLE L (UPPER)            T19 ED BPP Washington    None    None\n"
          ]
        }
      ],
      "source": [
        "# Create a summary DataFrame of locations missing coordinates\n",
        "# This will be useful for manually adding coordinates later\n",
        "missing_coords_summary = df_2025_prep[~df_2025_prep['has_coords']][\n",
        "    ['WATER', 'TOWN', 'COUNTY']\n",
        "].drop_duplicates().sort_values(['COUNTY', 'TOWN', 'WATER'])\n",
        "\n",
        "# Add columns for manually entering coordinates (initially blank)\n",
        "missing_coords_summary['X_coord'] = None\n",
        "missing_coords_summary['Y_coord'] = None\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"SUMMARY: Locations Missing Coordinates\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nTotal unique locations missing coordinates: {len(missing_coords_summary)}\")\n",
        "if len(missing_coords_summary) > 0:\n",
        "    print(f\"\\nBreakdown by county:\")\n",
        "    print(missing_coords_summary['COUNTY'].value_counts())\n",
        "    print(f\"\\nFirst 20 locations (full list below):\")\n",
        "    print(missing_coords_summary.head(20).to_string(index=False))\n",
        "else:\n",
        "    print(\"\\n✅ All locations have coordinates!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved missing coordinates to 'missing_coordinates_2025.csv'\n",
            "\n",
            "This file can be used to manually add coordinates.\n",
            "After adding coordinates, you can use this file to update the main dataset.\n"
          ]
        }
      ],
      "source": [
        "# Save missing coordinates to CSV for manual coordinate entry\n",
        "missing_coords_summary.to_csv('missing_coordinates_2025.csv', index=False)\n",
        "print(\"✅ Saved missing coordinates to 'missing_coordinates_2025.csv'\")\n",
        "print(f\"\\nThis file can be used to manually add coordinates.\")\n",
        "print(f\"After adding coordinates, you can use this file to update the main dataset.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. **Review the missing coordinates list** - Check `missing_coordinates_2025.csv`\n",
        "2. **Manually add coordinates** - Fill in X_coord and Y_coord columns for new locations\n",
        "3. **Create update script** - Build a script that:\n",
        "   - Loads 2025 data\n",
        "   - Merges in coordinates (from existing data + manually added)\n",
        "   - Combines with permanent species data (pike and char)\n",
        "   - Saves as updated `df_updated.csv`\n",
        "4. **Update the map** - The map will automatically use the new data\n",
        "\n",
        "**Note:** The lakefish survey data (`LakeFish_Maine.xls`) is available but will be handled separately in the future.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DATA SUMMARY\n",
            "================================================================================\n",
            "\n",
            "2025 Stocking Data:\n",
            "  Total rows: 2207\n",
            "  Unique locations: 921\n",
            "  Species: BROOK TROUT, BROWN TROUT, L.L. SALMON, LAKE TROUT, RAINBOW TROUT, SPLAKE\n",
            "  Columns: TOWN, DATE, WATER, COUNTY, SPECIES, QTY, SIZE (inch), X_coord, Y_coord, key, has_coords\n",
            "\n",
            "Current Combined Data:\n",
            "  Total rows: 1232\n",
            "  Stocked species rows: 1189\n",
            "  Permanent species rows (to keep): 43\n",
            "\n",
            "Coordinate Status:\n",
            "  Locations with coordinates: 2189 rows\n",
            "  Locations missing coordinates: 18 rows\n",
            "  Unique locations missing coordinates: 13\n",
            "\n",
            "Comparison (2024 vs 2025):\n",
            "  New locations in 2025: 13\n",
            "  Removed locations from 2024: 8\n",
            "  Locations in both: 908\n"
          ]
        }
      ],
      "source": [
        "# Quick stats summary\n",
        "print(\"=\" * 80)\n",
        "print(\"DATA SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n2025 Stocking Data:\")\n",
        "print(f\"  Total rows: {len(df_2025_prep)}\")\n",
        "print(f\"  Unique locations: {len(unique_2025_locations_clean)}\")\n",
        "print(f\"  Species: {', '.join(sorted(df_2025_prep['SPECIES'].dropna().unique()))}\")\n",
        "print(f\"  Columns: {', '.join(df_2025_prep.columns.tolist())}\")\n",
        "\n",
        "print(f\"\\nCurrent Combined Data:\")\n",
        "print(f\"  Total rows: {len(df_current)}\")\n",
        "print(f\"  Stocked species rows: {len(current_stocked)}\")\n",
        "print(f\"  Permanent species rows (to keep): {len(permanent_data)}\")\n",
        "\n",
        "print(f\"\\nCoordinate Status:\")\n",
        "print(f\"  Locations with coordinates: {df_2025_prep['has_coords'].sum()} rows\")\n",
        "print(f\"  Locations missing coordinates: {(~df_2025_prep['has_coords']).sum()} rows\")\n",
        "print(f\"  Unique locations missing coordinates: {len(missing_coords_summary)}\")\n",
        "\n",
        "print(f\"\\nComparison (2024 vs 2025):\")\n",
        "print(f\"  New locations in 2025: {len(new_locations)}\")\n",
        "print(f\"  Removed locations from 2024: {len(removed_locations)}\")\n",
        "print(f\"  Locations in both: {len(set_2024 & set_2025)}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
